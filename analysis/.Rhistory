family = poisson)
plot(exp(predict(lenModel)),as.numeric(lenfreq),
main=l)
abline(0,1)
predictedLenFreq =
exp(predict(lenModel,
newdata=data.frame(
wordLength=missingVals)))
names(predictedLenFreq) = missingVals
lenfreq = c(lenfreq,predictedLenFreq)
}
lenfreq = lenfreq/sum(lenfreq)
dataloan2[sel,]$source.language.word.freq =
lenfreq[match(dataloan2[sel,]$source.word.length,
as.numeric(names(lenfreq)))]
}
mean.lengths = tapply(asjp.words$Form, asjp.words$Language_ID, function(X){mean(nchar(X))})
dataloan2$source.language.mean.word.length =
mean.lengths[asjp.codes[match(dataloan2$source.language,asjp.codes$name),]$asjp.ID]
#dataloan2$source.language.mean.word.length[is.na(dataloan2$source.language)] = mean.lengths["ENGLISH"]
dataloan2$source.language.word.freq = NA
dataloan2$source.word.length = nchar(dataloan2$source.word)
dataloan2[is.na(dataloan2$source.word.length),]$source.word.length = dataloan2[is.na(dataloan2$source.word.length),]$phonlength
langs= as.character(unique(dataloan2$source.language))
langs = langs[!is.na(langs)]
langs = langs[langs!="Unidentified"]
for(l in langs){
sel = dataloan2$source.language==l & !is.na(dataloan2$source.language)
lwords = asjp.words[asjp.words$Language_ID ==
asjp.codes[match(l,asjp.codes$name),]$asjp.ID,]$Form
lenfreq = table(nchar(lwords))
wordLength = as.numeric(names(lenfreq))
lengthsNeeded = sort(unique(dataloan2[sel,]$source.word.length))
if(!all(lengthsNeeded %in% wordLength)){
# fit a poisson regression to the data to
# fill in missing values
missingVals = setdiff(lengthsNeeded,wordLength)
print(paste("Pred",length(missingVals),"vals for",l))
lenModel = glm(as.numeric(lenfreq) ~
wordLength +
I(wordLengt^2),
family = poisson)
plot(exp(predict(lenModel)),as.numeric(lenfreq),
main=l)
abline(0,1)
predictedLenFreq =
exp(predict(lenModel,
newdata=data.frame(
wordLength=missingVals)))
names(predictedLenFreq) = missingVals
lenfreq = c(lenfreq,predictedLenFreq)
}
lenfreq = lenfreq/sum(lenfreq)
dataloan2[sel,]$source.language.word.freq =
lenfreq[match(dataloan2[sel,]$source.word.length,
as.numeric(names(lenfreq)))]
}
for(l in langs){
sel = dataloan2$source.language==l & !is.na(dataloan2$source.language)
lwords = asjp.words[asjp.words$Language_ID ==
asjp.codes[match(l,asjp.codes$name),]$asjp.ID,]$Form
lenfreq = table(nchar(lwords))
wordLength = as.numeric(names(lenfreq))
lengthsNeeded = sort(unique(dataloan2[sel,]$source.word.length))
if(!all(lengthsNeeded %in% wordLength)){
# fit a poisson regression to the data to
# fill in missing values
missingVals = setdiff(lengthsNeeded,wordLength)
print(paste("Pred",length(missingVals),"vals for",l))
lenModel = glm(as.numeric(lenfreq) ~
wordLength +
I(wordLength^2),
family = poisson)
plot(exp(predict(lenModel)),as.numeric(lenfreq),
main=l)
abline(0,1)
predictedLenFreq =
exp(predict(lenModel,
newdata=data.frame(
wordLength=missingVals)))
names(predictedLenFreq) = missingVals
lenfreq = c(lenfreq,predictedLenFreq)
}
lenfreq = lenfreq/sum(lenfreq)
dataloan2[sel,]$source.language.word.freq =
lenfreq[match(dataloan2[sel,]$source.word.length,
as.numeric(names(lenfreq)))]
}
hist(dataloan2$source.language.word.freq)
max(dataloan2$source.language.word.freq)
max(dataloan2$source.language.word.freq,na.rm=T)
# Get data from the ASJP.
#  - Work out the average word length for each language
#  - For each borrowed word, work out the frequency of having a word of that length in the source language
#  Missing values are filled in by regression
try(setwd("~/Documents/MPI/MonaghanAoA/Stats 2/processing/"))
dataloan2 = read.csv("../data/loanword8.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
dataloan2[is.na(dataloan2$source.language),]$source.language = "English"
glottocodes = c(
"English" = "stan1293",
"French" = "stan1290",
"Latin" = "lati1261",
"Dharuk" = "sydn1236",
"Guugu Yimidhirr" = "gugu1255",
"Tahitian" = "tahi1242",
"Spanish" = "stan1288",
"Late Latin" = "lati1261",
"Narragansett" = "pequ1242",# Mohegan, which is part of the same dialect chain as Narragansett 'mohe1244',
"French (Anglo-Norman)" = "stan1290",# Substituting standard french (not much else in ASJP)
"Eastern Abenaki" = "east2544",
"Algonquian (Powhatan)" = "powh1243",
"Tupí" = "tupi1273",# Substituting Tupinamba instead of Tupi "tupi1274",
"Dutch" = "dutc1256",
"Italian" = "ital1282",
"Portuguese" = "port1283",
"Middle French" = "stan1290",
"Welsh" = "wels1247",
"Old Norse" = "oldn1244",
"Gaelic (Scottish)" = "scot1245",
"Middle Low German" = "nort2627",# Subsituting Eastern low german instead of Middle Low German "midd1318",
"Greek" = "anci1242",
"Vulgar Latin" = "lati1261",
"Malay" = "mala1479",
"Middle North Germanic" = "oldh1241",# Old high german
"Middle High German"= "oldh1241",# Old high german,
"Middle Dutch" = "dutc1256" # Modern dutch
)
asjp.lang = read.csv("../data/asjp_dataset.cldf/languages.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
asjp.codes = data.frame(
name = names(glottocodes),
glottocode = glottocodes,
asjp.ID = asjp.lang[match(glottocodes,asjp.lang$Glottocode),]$ID
)
asjp.codes = rbind(
asjp.codes,
data.frame(
name = c("Celtic",'Old French',"French (Walloon)","Norwegian"),
glottocode = c(NA,NA),
asjp.ID = c("PROTO_CELTIC","WALLOON","WALLOON","NORWEGIAN_BOKMAAL")
)
)
asjp.codes[is.na(asjp.codes$asjp.ID),]
asjp.words = read.csv("../data/asjp_dataset.cldf/forms.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
asjp.words = asjp.words[asjp.words$Language_ID %in% asjp.codes$asjp.ID,]
# Clean forms
asjp.words$Form = gsub("[\\*~ \\$]","",asjp.words$Form)
# Mean lengths
mean.lengths = tapply(asjp.words$Form, asjp.words$Language_ID, function(X){mean(nchar(X))})
dataloan2$source.language.mean.word.length =
mean.lengths[asjp.codes[match(dataloan2$source.language,asjp.codes$name),]$asjp.ID]
#dataloan2$source.language.mean.word.length[is.na(dataloan2$source.language)] = mean.lengths["ENGLISH"]
dataloan2$source.language.word.freq = NA
dataloan2$source.word.length = nchar(dataloan2$source.word)
dataloan2[is.na(dataloan2$source.word.length),]$source.word.length = dataloan2[is.na(dataloan2$source.word.length),]$phonlength
langs= as.character(unique(dataloan2$source.language))
langs = langs[!is.na(langs)]
langs = langs[langs!="Unidentified"]
for(l in langs){
sel = dataloan2$source.language==l & !is.na(dataloan2$source.language)
lwords = asjp.words[asjp.words$Language_ID ==
asjp.codes[match(l,asjp.codes$name),]$asjp.ID,]$Form
lenfreq = table(nchar(lwords))
wordLength = as.numeric(names(lenfreq))
lengthsNeeded = sort(unique(dataloan2[sel,]$source.word.length))
if(!all(lengthsNeeded %in% wordLength)){
# fit a poisson regression to the data to
# fill in missing values
missingVals = setdiff(lengthsNeeded,wordLength)
print(paste("Pred",length(missingVals),"vals for",l))
lenModel = glm(as.numeric(lenfreq) ~
wordLength +
I(wordLength^2),
family = poisson)
plot(exp(predict(lenModel)),as.numeric(lenfreq),
main=l)
abline(0,1)
predictedLenFreq =
exp(predict(lenModel,
newdata=data.frame(
wordLength=missingVals)))
names(predictedLenFreq) = missingVals
lenfreq = c(lenfreq,predictedLenFreq)
}
lenfreq = lenfreq/sum(lenfreq)
dataloan2[sel,]$source.language.word.freq =
lenfreq[match(dataloan2[sel,]$source.word.length,
as.numeric(names(lenfreq)))]
}
dataloan2 = dataloan2[,!names(dataloan2) %in%c("X","X.1","X.4","X.3","X.2","nounornot","verbornot","adjornot","advornot","pronounornot","functionornot","numberornot")]
write.csv(dataloan2, "../data/loanword9.csv", row.names = F)
hist(dataloan2$source.language.word.freq)
hist(dataloan2$source.language.mean.word.length)
# Get data from the ASJP.
#  - Work out the average word length for each language
#  - For each borrowed word, work out the frequency of having a word of that length in the source language
#  Missing values are filled in by regression
try(setwd("~/Documents/MPI/MonaghanAoA/Stats 2/processing/"))
dataloan2 = read.csv("../data/loanword8.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
dataloan2[is.na(dataloan2$source.language),]$source.language = "English"
glottocodes = c(
"English" = "stan1293",
"French" = "stan1290",
"Latin" = "lati1261",
"Dharuk" = "sydn1236",
"Guugu Yimidhirr" = "gugu1255",
"Tahitian" = "tahi1242",
"Spanish" = "stan1288",
"Late Latin" = "lati1261", # Latin
"Narragansett" = "pequ1242",# Mohegan, which is part of the same dialect chain as Narragansett 'mohe1244',
"French (Anglo-Norman)" = "stan1290",# Substituting standard french (not much else in ASJP)
"Eastern Abenaki" = "east2544",
"Algonquian (Powhatan)" = "powh1243",
"Tupí" = "tupi1273",# Substituting Tupinamba instead of Tupi "tupi1274",
"Dutch" = "dutc1256",
"Italian" = "ital1282",
"Portuguese" = "port1283",
"Middle French" = "stan1290",
"Welsh" = "wels1247",
"Old Norse" = "oldn1244",
"Gaelic (Scottish)" = "scot1245",
"Middle Low German" = "nort2627",# Subsituting Eastern low german instead of Middle Low German "midd1318",
"Greek" = "anci1242", # Ancient greek
"Vulgar Latin" = "lati1261", # Latin
"Malay" = "mala1479",
"Middle North Germanic" = "oldh1241",# Old high german
"Middle High German"= "oldh1241",# Old high german,
"Middle Dutch" = "dutc1256" # Modern dutch
)
asjp.lang = read.csv("../data/asjp_dataset.cldf/languages.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
asjp.codes = data.frame(
name = names(glottocodes),
glottocode = glottocodes,
asjp.ID = asjp.lang[match(glottocodes,asjp.lang$Glottocode),]$ID
)
asjp.codes = rbind(
asjp.codes,
data.frame(
name = c("Celtic",'Old French',"French (Walloon)","Norwegian"),
glottocode = c(NA,NA),
asjp.ID = c("PROTO_CELTIC","WALLOON","WALLOON","NORWEGIAN_BOKMAAL")
)
)
asjp.codes[is.na(asjp.codes$asjp.ID),]
asjp.words = read.csv("../data/asjp_dataset.cldf/forms.csv",stringsAsFactors = F, encoding = "UTF-8",fileEncoding = "UTF-8")
asjp.words = asjp.words[asjp.words$Language_ID %in% asjp.codes$asjp.ID,]
# Clean forms
asjp.words$Form = gsub("[\\*~ \\$]","",asjp.words$Form)
# Mean lengths
mean.lengths = tapply(asjp.words$Form, asjp.words$Language_ID, function(X){mean(nchar(X))})
dataloan2$source.language.mean.word.length =
mean.lengths[asjp.codes[match(dataloan2$source.language,asjp.codes$name),]$asjp.ID]
#dataloan2$source.language.mean.word.length[is.na(dataloan2$source.language)] = mean.lengths["ENGLISH"]
dataloan2$source.language.word.freq = NA
dataloan2$source.word.length = nchar(dataloan2$source.word)
dataloan2[is.na(dataloan2$source.word.length),]$source.word.length = dataloan2[is.na(dataloan2$source.word.length),]$phonlength
langs= as.character(unique(dataloan2$source.language))
langs = langs[!is.na(langs)]
langs = langs[langs!="Unidentified"]
for(l in langs){
sel = dataloan2$source.language==l & !is.na(dataloan2$source.language)
lwords = asjp.words[asjp.words$Language_ID ==
asjp.codes[match(l,asjp.codes$name),]$asjp.ID,]$Form
lenfreq = table(nchar(lwords))
wordLength = as.numeric(names(lenfreq))
lengthsNeeded = sort(unique(dataloan2[sel,]$source.word.length))
if(!all(lengthsNeeded %in% wordLength)){
# fit a poisson regression to the data to
# fill in missing values
missingVals = setdiff(lengthsNeeded,wordLength)
print(paste("Pred",length(missingVals),"vals for",l))
lenModel = glm(as.numeric(lenfreq) ~
wordLength +
I(wordLength^2),
family = poisson)
plot(exp(predict(lenModel)),as.numeric(lenfreq),
main=l)
abline(0,1)
predictedLenFreq =
exp(predict(lenModel,
newdata=data.frame(
wordLength=missingVals)))
names(predictedLenFreq) = missingVals
lenfreq = c(lenfreq,predictedLenFreq)
}
lenfreq = lenfreq/sum(lenfreq)
dataloan2[sel,]$source.language.word.freq =
lenfreq[match(dataloan2[sel,]$source.word.length,
as.numeric(names(lenfreq)))]
}
dataloan2 = dataloan2[,!names(dataloan2) %in%c("X","X.1","X.4","X.3","X.2","nounornot","verbornot","adjornot","advornot","pronounornot","functionornot","numberornot")]
write.csv(dataloan2, "../data/loanword9.csv", row.names = F)
hist(dataloan2$source.language.word.freq)
---
title: "Cognitive influences in language evolution: English data"
output:
pdf_document:
toc: true
---
# Introduction
This is the model code for Monaghan & Roberts, "Cognitive influences in language evolution: Psycholinguistic predictors of loan word borrowing".  It takes data from the WOLD database of borrowing for English and tries to predict whether a word has been borrowed or not according to various psycholinguitic measures.
The main fields in the data frame are:
-  word: Orthographic form
-  borrowing: variable from WOLD indicating level of evidence for borrowing:
-  1 = definately borrowed
-  5 = no evidence of borrowing
-  age_oldest, age_youngest: Dates from WOLD indicating estiamte of data of entry into English
-  phonology:  Phonological form
-  phonlength:  Number of segments in the phonological form
-  AoA: Age of acquisition ratings from Kuperman, Stadthagen-Gonzalez, and Brysbaert (2012).
-  AoA_obj: Objective, test-based age of acuqisition from Brysbaert & Biemiller (2017)
-  subtlexzipf:  Log frequency of word from the SUBTLEX database
-  conc:  Concreteness ratings from Brysbaert, Warriner, & Kuperman (2014)
-  cat: Dominant part of speech according to SUBTLEX.
-  bor15:  Conversion of the WOLD borrowing variable into a numeric (0 = not borrowed, 1 = borrowed)
```{r echo=F,eval=F}
setwd("~/Documents/MPI/MonaghanAoA/Stats 2/analysis/")
```
# Load libraries
```{r warning=F, message=F}
library(mgcv)
library(sjPlot)
library(lattice)
library(ggplot2)
library(dplyr)
library(party)
library(lmtest)
library(gridExtra)
library(scales)
library(itsadug)
library(ggfortify)
library(factoextra)
library(gridExtra)
library(reshape2)
library(binom)
logit2per = function(X){
return(exp(X)/(1+exp(X)))
}
rescaleGam = function(px, n, xvar, xlab=""){
y = logit2per(px[[n]]$fit)
x = px[[n]]$x *attr(xvar,"scaled:scale") + attr(xvar,"scaled:center")
se.upper = logit2per(px[[n]]$fit+px[[n]]$se)
se.lower = logit2per(px[[n]]$fit-px[[n]]$se)
dx = data.frame(x=x,y=y,ci.upper=se.upper,ci.lower=se.lower)
plen = ggplot(dx, aes(x=x,y=y))+
geom_ribbon(aes(ymin=ci.lower,ymax=ci.upper), alpha=0.3)+
geom_line(size=1) +
xlab(xlab)+
ylab("Probability of borrowing")+
coord_cartesian(ylim = c(0,1))
return(plen)
}
# Code for assessing significance of GAM slopes
source("GAM_derivaties.R")
```
# Load data
```{r}
dataloan <- read.csv("../data/loanword9.csv",stringsAsFactors = F)
dataloan$bor15 <- ifelse(dataloan$borrowing==1,1, ifelse(dataloan$borrowing==5,0,NA))
dataloan$bor15.cat <- factor(dataloan$bor15)
```
Convert to numbers.
```{r warning=F}
dataloan$subtlexzipf = as.numeric(dataloan$subtlexzipf)
dataloan$AoA = as.numeric(dataloan$AoA)
dataloan$conc = as.numeric(dataloan$conc)
aoaSD = sd(dataloan$AoA,na.rm = T)
aoaMean = mean(dataloan$AoA/aoaSD,na.rm=T)
dataloan$cat = factor(dataloan$cat)
```
Select only complete cases.
```{r}
dataloan2 = dataloan[complete.cases(dataloan[,
c("phonlength","AoA",
"subtlexzipf", "cat",
'conc','bor15')]),]
```
Scale and center:
```{r}
dataloan2$AoAscale <- scale(dataloan2$AoA)
dataloan2$subtlexzipfscale <- scale(dataloan2$subtlexzipf)
phonlength.center = median(dataloan2$phonlength)
dataloan2$phonlengthscale <-
dataloan2$phonlength - phonlength.center
phonlength.scale = sd(dataloan2$phonlengthscale)
dataloan2$phonlengthscale = dataloan2$phonlengthscale/phonlength.scale
attr(dataloan2$phonlengthscale,"scaled:scale") = phonlength.scale
attr(dataloan2$phonlengthscale,"scaled:center") = phonlength.center
dataloan2$concscale <- scale(dataloan2$conc)
conc.scale = attr(dataloan2$concscale,"scaled:scale")
conc.center = attr(dataloan2$concscale,"scaled:center")
dataloan2$cat = relevel(dataloan2$cat,"Noun")
dataloan2$AoA_objscaled = scale(dataloan2$AoA_obj)
dataloan2$source.language[dataloan2$bor15==0] = "English"
dataloan2$source.language = factor(dataloan2$source.language)
dataloan2$SLMWL = scale(log(dataloan2$source.language.mean.word.length))
dataloan2$SWF = scale(dataloan2$source.language.word.freq)
```
Identify Swadesh words:
```{r}
swd = read.csv("../data/SwadeshConcepts.txt", header = F, stringsAsFactors = F)$V1
dataloan2$Swadesh = dataloan2$word %in% swd
```
\newpage
# Plots
Raw data
```{r}
dataloan2$Borrowed = c("Not borrowed", "Borrowed")[dataloan2$bor15+1]
ggplot(dataloan2[!is.na(dataloan2$Borrowed),], aes(x=AoA, colour=Borrowed)) +
geom_density()
ggplot(dataloan2[!is.na(dataloan2$Borrowed),], aes(x=as.numeric(subtlexzipfscale), colour=Borrowed)) +
geom_density()
ggplot(dataloan2[!is.na(dataloan2$Borrowed),], aes(x=as.numeric(subtlexzipf), y=bor15)) +
stat_smooth()+
xlab("Frequency")
ggplot(dataloan2[!is.na(dataloan2$Borrowed),], aes(x=as.numeric(phonlength), y=bor15)) +
stat_smooth() +
xlab("Length")
dataloan2$subtlexzipf.cat = cut(
dataloan2$subtlexzipf,
breaks = quantile(dataloan2$subtlexzipf,
prob=seq(0,1,length.out=4)),
include.lowest = T)
```
Look at variation between parts of speech.  We calculate the means, but the number of observations is very different for each category.  We estimate confidence intervals around the mean with Wilson's binomial confidence interval method.
```{r}
catx = data.frame(
PoS = tapply(dataloan2$cat, dataloan2$cat, function(X){as.character(X[1])}),
mean = tapply(dataloan2$bor15, dataloan2$cat, mean),
n = tapply(dataloan2$bor15, dataloan2$cat, length),
confint = binom.confint(
tapply(dataloan2$bor15, dataloan2$cat, sum),
tapply(dataloan2$bor15, dataloan2$cat, length),
methods="wilson"
)
)
catx = catx[order(catx$confint.lower, decreasing = T),]
catx$PoS = factor(catx$PoS, levels = catx[order(catx$confint.lower, decreasing = T),]$PoS)
posg = ggplot(catx, aes(x=mean, y=PoS)) +
geom_point(size=2) +
ylab("Part of speech") +
xlab("Proportion of words borrowed")+
scale_x_continuous(labels=percent_format()) +
geom_text(aes(label=n), nudge_y=0.4) +
geom_errorbarh(aes(xmin=confint.lower, xmax=confint.upper))
posg
pdf("../results/graphs/POS_Borrowing.pdf",
width = 6,
height = 4)
posg
dev.off()
catx$mean= catx$mean*100
catx$confint.lower= catx$confint.lower*100
catx$confint.upper= catx$confint.upper*100
write.csv(catx[,c("PoS","mean",
'n','confint.lower','confint.upper')],
"../results/English_POS_BorrowingProportions.csv",
row.names = F)
```
\newpage
# GAM
```{r}
m0 = bam(bor15.cat ~
s(phonlengthscale) +
s(AoAscale) +
s(subtlexzipfscale) +
s(concscale) +
s(cat,bs='re')+
s(cat,phonlengthscale,bs='re')+
s(cat,AoAscale,bs='re')+
s(cat,subtlexzipfscale,bs='re')+
s(cat,concscale,bs='re'),
data = dataloan2,
family='binomial')
```
```{r}
summary(m0)
```
```{r}
mLenControl = update(m0, ~.+s(SWF,k=3))
summary(mLenControl)
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
plot(mLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
plot(mLenControl)
plot(mLenControl)
?plot.gam()
plot(mLenControl,select="s(SLMWL,k=3)")
plot(mLenControl,select=8)
plot(mLenControl,select=10)
plot(mLenControl,select=11)
plot(mLenControl,select=11)
plot(mLenControl,select=10)
mLenFreqControl = update(m0, ~.+s(SWF,k=3))
plot(mLenFreqControl,select=10)
mMeanLenControl = update(m0, ~.+s(SLMWL,k=3))
summary(mMeanLenControl)
plot(mMeanLenControl,select=10)
mx.labels = c("Length","AoA","Frequency","Concreteness")
par(mfrow=c(2,2),mar=c(2,2,1,2))
for(i in 1:4){
plot(m0,select=i,main=mx.labels[i],ylim=c(-4,4))
par(new=T)
plot(mMeanLenControl,select=i,ylim=c(-4,4), col=2,ylab="")
legend(-1,-1.5,legend = c("Original","With length control"),col=1:2,lty=1, bty='n')
}
par(mfrow=c(1,1))
